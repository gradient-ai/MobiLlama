{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa7a9d09-4d86-4174-89bd-96efb8f228ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T14:12:23.653784Z",
     "iopub.status.busy": "2024-03-04T14:12:23.653053Z",
     "iopub.status.idle": "2024-03-04T14:12:35.450373Z",
     "shell.execute_reply": "2024-03-04T14:12:35.449323Z",
     "shell.execute_reply.started": "2024-03-04T14:12:23.653729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.21.3)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3\n",
      "  Downloading huggingface_hub-0.21.3-py3-none-any.whl (346 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.2/346.2 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.64.1)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.23.4)\n",
      "Collecting tokenizers<0.19,>=0.14\n",
      "  Downloading tokenizers-0.15.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.9/170.9 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.14)\n",
      "Installing collected packages: safetensors, fsspec, huggingface-hub, tokenizers, transformers\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.1.0\n",
      "    Uninstalling fsspec-2023.1.0:\n",
      "      Successfully uninstalled fsspec-2023.1.0\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.12.0\n",
      "    Uninstalling huggingface-hub-0.12.0:\n",
      "      Successfully uninstalled huggingface-hub-0.12.0\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.12.1\n",
      "    Uninstalling tokenizers-0.12.1:\n",
      "      Successfully uninstalled tokenizers-0.12.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.21.3\n",
      "    Uninstalling transformers-4.21.3:\n",
      "      Successfully uninstalled transformers-4.21.3\n",
      "Successfully installed fsspec-2024.2.0 huggingface-hub-0.21.3 safetensors-0.4.2 tokenizers-0.15.2 transformers-4.38.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -U transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f665661e-6358-4464-8b57-84ca72891cd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T14:14:05.009764Z",
     "iopub.status.busy": "2024-03-04T14:14:05.009111Z",
     "iopub.status.idle": "2024-03-04T14:14:06.218829Z",
     "shell.execute_reply": "2024-03-04T14:14:06.218197Z",
     "shell.execute_reply.started": "2024-03-04T14:14:05.009734Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "281b60cc-9a24-4e3a-bfe4-bdecc526a782",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T14:14:08.342202Z",
     "iopub.status.busy": "2024-03-04T14:14:08.341265Z",
     "iopub.status.idle": "2024-03-04T14:14:08.885623Z",
     "shell.execute_reply": "2024-03-04T14:14:08.885000Z",
     "shell.execute_reply.started": "2024-03-04T14:14:08.342143Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"MBZUAI/MobiLlama-1B-Chat\", trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "071d7303-dae4-4202-a7ea-41cd969e8d9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T14:14:12.546490Z",
     "iopub.status.busy": "2024-03-04T14:14:12.546112Z",
     "iopub.status.idle": "2024-03-04T14:14:34.659773Z",
     "shell.execute_reply": "2024-03-04T14:14:34.659200Z",
     "shell.execute_reply.started": "2024-03-04T14:14:12.546443Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d25cdbfd754506b3e22d4977153121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.52G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac9ea95b0c6049b1b6bf2b2ab293ca8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(\"MBZUAI/MobiLlama-1B-Chat\", trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a405c319-2750-411c-b831-e6229d2ca52e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T14:13:39.021236Z",
     "iopub.status.busy": "2024-03-04T14:13:39.020708Z",
     "iopub.status.idle": "2024-03-04T14:13:48.502854Z",
     "shell.execute_reply": "2024-03-04T14:13:48.502055Z",
     "shell.execute_reply.started": "2024-03-04T14:13:39.021213Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flash_attn\n",
      "  Downloading flash_attn-2.5.6.tar.gz (2.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from flash_attn) (1.12.1+cu116)\n",
      "Collecting einops\n",
      "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from flash_attn) (23.0)\n",
      "Collecting ninja\n",
      "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->flash_attn) (4.4.0)\n",
      "Building wheels for collected packages: flash_attn\n",
      "  Building wheel for flash_attn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for flash_attn: filename=flash_attn-2.5.6-cp39-cp39-linux_x86_64.whl size=121711102 sha256=d27c90d0bb68f59e447a57db79b70ea204a2adc60b9961dee0f7e677947c56bd\n",
      "  Stored in directory: /root/.cache/pip/wheels/68/e9/30/3cd6f67ab35cea745ea3300624d6ce0f41b5af93e3b50d3553\n",
      "Successfully built flash_attn\n",
      "Installing collected packages: ninja, einops, flash_attn\n",
      "Successfully installed einops-0.7.0 flash_attn-2.5.6 ninja-1.11.1.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install flash_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cf93439-f7ba-4522-abee-dcc122bc8a16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T14:14:46.424358Z",
     "iopub.status.busy": "2024-03-04T14:14:46.423325Z",
     "iopub.status.idle": "2024-03-04T14:14:49.330473Z",
     "shell.execute_reply": "2024-03-04T14:14:49.329889Z",
     "shell.execute_reply.started": "2024-03-04T14:14:46.424320Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobiLlamaForCausalLM(\n",
       "  (model): MobiLlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0): MobiLlamaDecoderLayer(\n",
       "        (self_attn): MobiLlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): MobiLlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MobiLlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MobiLlamaRMSNorm()\n",
       "        (post_attention_layernorm): MobiLlamaRMSNorm()\n",
       "      )\n",
       "      (1): MobiLlamaDecoderLayer(\n",
       "        (self_attn): MobiLlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): MobiLlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MobiLlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MobiLlamaRMSNorm()\n",
       "        (post_attention_layernorm): MobiLlamaRMSNorm()\n",
       "      )\n",
       "      (2): MobiLlamaDecoderLayer(\n",
       "        (self_attn): MobiLlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): MobiLlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MobiLlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MobiLlamaRMSNorm()\n",
       "        (post_attention_layernorm): MobiLlamaRMSNorm()\n",
       "      )\n",
       "      (3): MobiLlamaDecoderLayer(\n",
       "        (self_attn): MobiLlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): MobiLlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MobiLlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MobiLlamaRMSNorm()\n",
       "        (post_attention_layernorm): MobiLlamaRMSNorm()\n",
       "      )\n",
       "      (4): MobiLlamaDecoderLayer(\n",
       "        (self_attn): MobiLlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): MobiLlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MobiLlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MobiLlamaRMSNorm()\n",
       "        (post_attention_layernorm): MobiLlamaRMSNorm()\n",
       "      )\n",
       "      (5): MobiLlamaDecoderLayer(\n",
       "        (self_attn): MobiLlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): MobiLlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MobiLlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MobiLlamaRMSNorm()\n",
       "        (post_attention_layernorm): MobiLlamaRMSNorm()\n",
       "      )\n",
       "      (6): MobiLlamaDecoderLayer(\n",
       "        (self_attn): MobiLlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): MobiLlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MobiLlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MobiLlamaRMSNorm()\n",
       "        (post_attention_layernorm): MobiLlamaRMSNorm()\n",
       "      )\n",
       "      (7): MobiLlamaDecoderLayer(\n",
       "        (self_attn): MobiLlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): MobiLlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MobiLlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MobiLlamaRMSNorm()\n",
       "        (post_attention_layernorm): MobiLlamaRMSNorm()\n",
       "      )\n",
       "      (8): MobiLlamaDecoderLayer(\n",
       "        (self_attn): MobiLlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): MobiLlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MobiLlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MobiLlamaRMSNorm()\n",
       "        (post_attention_layernorm): MobiLlamaRMSNorm()\n",
       "      )\n",
       "      (9): MobiLlamaDecoderLayer(\n",
       "        (self_attn): MobiLlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): MobiLlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MobiLlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MobiLlamaRMSNorm()\n",
       "        (post_attention_layernorm): MobiLlamaRMSNorm()\n",
       "      )\n",
       "      (10): MobiLlamaDecoderLayer(\n",
       "        (self_attn): MobiLlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): MobiLlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MobiLlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MobiLlamaRMSNorm()\n",
       "        (post_attention_layernorm): MobiLlamaRMSNorm()\n",
       "      )\n",
       "      (11): MobiLlamaDecoderLayer(\n",
       "        (self_attn): MobiLlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): MobiLlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MobiLlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MobiLlamaRMSNorm()\n",
       "        (post_attention_layernorm): MobiLlamaRMSNorm()\n",
       "      )\n",
       "      (12): MobiLlamaDecoderLayer(\n",
       "        (self_attn): MobiLlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): MobiLlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MobiLlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MobiLlamaRMSNorm()\n",
       "        (post_attention_layernorm): MobiLlamaRMSNorm()\n",
       "      )\n",
       "      (13): MobiLlamaDecoderLayer(\n",
       "        (self_attn): MobiLlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): MobiLlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MobiLlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MobiLlamaRMSNorm()\n",
       "        (post_attention_layernorm): MobiLlamaRMSNorm()\n",
       "      )\n",
       "      (14): MobiLlamaDecoderLayer(\n",
       "        (self_attn): MobiLlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): MobiLlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MobiLlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MobiLlamaRMSNorm()\n",
       "        (post_attention_layernorm): MobiLlamaRMSNorm()\n",
       "      )\n",
       "      (15): MobiLlamaDecoderLayer(\n",
       "        (self_attn): MobiLlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): MobiLlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MobiLlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MobiLlamaRMSNorm()\n",
       "        (post_attention_layernorm): MobiLlamaRMSNorm()\n",
       "      )\n",
       "      (16): MobiLlamaDecoderLayer(\n",
       "        (self_attn): MobiLlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): MobiLlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MobiLlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MobiLlamaRMSNorm()\n",
       "        (post_attention_layernorm): MobiLlamaRMSNorm()\n",
       "      )\n",
       "      (17): MobiLlamaDecoderLayer(\n",
       "        (self_attn): MobiLlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): MobiLlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MobiLlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MobiLlamaRMSNorm()\n",
       "        (post_attention_layernorm): MobiLlamaRMSNorm()\n",
       "      )\n",
       "      (18): MobiLlamaDecoderLayer(\n",
       "        (self_attn): MobiLlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): MobiLlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MobiLlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MobiLlamaRMSNorm()\n",
       "        (post_attention_layernorm): MobiLlamaRMSNorm()\n",
       "      )\n",
       "      (19): MobiLlamaDecoderLayer(\n",
       "        (self_attn): MobiLlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): MobiLlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MobiLlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MobiLlamaRMSNorm()\n",
       "        (post_attention_layernorm): MobiLlamaRMSNorm()\n",
       "      )\n",
       "      (20): MobiLlamaDecoderLayer(\n",
       "        (self_attn): MobiLlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): MobiLlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MobiLlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MobiLlamaRMSNorm()\n",
       "        (post_attention_layernorm): MobiLlamaRMSNorm()\n",
       "      )\n",
       "      (21): MobiLlamaDecoderLayer(\n",
       "        (self_attn): MobiLlamaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (rotary_emb): MobiLlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): MobiLlamaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (down_proj): Linear(in_features=5632, out_features=2048, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=5632, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MobiLlamaRMSNorm()\n",
       "        (post_attention_layernorm): MobiLlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): MobiLlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cuda')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9572d94c-16c0-4950-86b8-6aa83e03c26e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T14:15:00.673033Z",
     "iopub.status.busy": "2024-03-04T14:15:00.672527Z",
     "iopub.status.idle": "2024-03-04T14:15:00.676994Z",
     "shell.execute_reply": "2024-03-04T14:15:00.676344Z",
     "shell.execute_reply.started": "2024-03-04T14:15:00.673009Z"
    }
   },
   "outputs": [],
   "source": [
    "template= \"A chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.\\n### Human: Got any creative ideas for a 10 year old’s birthday?\\n### Assistant: Of course! Here are some creative ideas for a 10-year-old's birthday party:\\n1. Treasure Hunt: Organize a treasure hunt in your backyard or nearby park. Create clues and riddles for the kids to solve, leading them to hidden treasures and surprises.\\n2. Science Party: Plan a science-themed party where kids can engage in fun and interactive experiments. You can set up different stations with activities like making slime, erupting volcanoes, or creating simple chemical reactions.\\n3. Outdoor Movie Night: Set up a backyard movie night with a projector and a large screen or white sheet. Create a cozy seating area with blankets and pillows, and serve popcorn and snacks while the kids enjoy a favorite movie under the stars.\\n4. DIY Crafts Party: Arrange a craft party where kids can unleash their creativity. Provide a variety of craft supplies like beads, paints, and fabrics, and let them create their own unique masterpieces to take home as party favors.\\n5. Sports Olympics: Host a mini Olympics event with various sports and games. Set up different stations for activities like sack races, relay races, basketball shooting, and obstacle courses. Give out medals or certificates to the participants.\\n6. Cooking Party: Have a cooking-themed party where the kids can prepare their own mini pizzas, cupcakes, or cookies. Provide toppings, frosting, and decorating supplies, and let them get hands-on in the kitchen.\\n7. Superhero Training Camp: Create a superhero-themed party where the kids can engage in fun training activities. Set up an obstacle course, have them design their own superhero capes or masks, and organize superhero-themed games and challenges.\\n8. Outdoor Adventure: Plan an outdoor adventure party at a local park or nature reserve. Arrange activities like hiking, nature scavenger hunts, or a picnic with games. Encourage exploration and appreciation for the outdoors.\\nRemember to tailor the activities to the birthday child's interests and preferences. Have a great celebration!\\n### Human: {prompt}\\n### Assistant:\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d811b29f-a7ec-4614-a9ec-b7be3b0bfa8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T14:15:06.907258Z",
     "iopub.status.busy": "2024-03-04T14:15:06.906395Z",
     "iopub.status.idle": "2024-03-04T14:15:06.910275Z",
     "shell.execute_reply": "2024-03-04T14:15:06.909597Z",
     "shell.execute_reply.started": "2024-03-04T14:15:06.907233Z"
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"What are the key benefits of practicing mindfulness meditation?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb3610e9-9268-4f72-83a7-7bdf9794d480",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T14:15:13.400828Z",
     "iopub.status.busy": "2024-03-04T14:15:13.400303Z",
     "iopub.status.idle": "2024-03-04T14:15:13.404203Z",
     "shell.execute_reply": "2024-03-04T14:15:13.403415Z",
     "shell.execute_reply.started": "2024-03-04T14:15:13.400803Z"
    }
   },
   "outputs": [],
   "source": [
    "input_str = template.format(prompt=prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7603513a-f737-46ac-baed-4cc53c245ef8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T14:15:22.679566Z",
     "iopub.status.busy": "2024-03-04T14:15:22.678688Z",
     "iopub.status.idle": "2024-03-04T14:15:22.703270Z",
     "shell.execute_reply": "2024-03-04T14:15:22.702697Z",
     "shell.execute_reply.started": "2024-03-04T14:15:22.679532Z"
    }
   },
   "outputs": [],
   "source": [
    "input_ids = tokenizer(input_str, return_tensors=\"pt\").to('cuda').input_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "093d014f-5495-4ee0-9689-beb18ed05914",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T14:15:31.080815Z",
     "iopub.status.busy": "2024-03-04T14:15:31.080043Z",
     "iopub.status.idle": "2024-03-04T14:15:36.731743Z",
     "shell.execute_reply": "2024-03-04T14:15:36.731055Z",
     "shell.execute_reply.started": "2024-03-04T14:15:31.080790Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs = model.generate(input_ids, max_length=1000, pad_token_id=tokenizer.eos_token_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "445ca07f-5d41-49ba-8d59-88b54be263a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T14:15:43.593643Z",
     "iopub.status.busy": "2024-03-04T14:15:43.592939Z",
     "iopub.status.idle": "2024-03-04T14:15:43.598341Z",
     "shell.execute_reply": "2024-03-04T14:15:43.597797Z",
     "shell.execute_reply.started": "2024-03-04T14:15:43.593617Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mindfulness meditation is a practice that helps individuals become more aware of their thoughts, emotions, and physical sensations. It has several key benefits, including:\n",
      "1. Reduced stress and anxiety: Mindfulness meditation can help reduce stress and anxiety by allowing individuals to focus on the present moment and reduce their thoughts and emotions.\n",
      "2. Improved sleep: Mindfulness meditation can help improve sleep quality by reducing stress and anxiety, which can lead to better sleep.\n",
      "3. Improved focus and concentration: Mindfulness meditation can help improve focus and concentration by allowing individuals to focus on the present moment and reduce their thoughts and emotions.\n",
      "4. Improved emotional regulation: Mindfulness meditation can help improve emotional regulation by allowing individuals to become more aware of their thoughts, emotions, and physical sensations.\n",
      "5. Improved overall well-being: Mindfulness meditation can help improve overall well-being by allowing individuals to become more aware of their thoughts, emotions, and physical sensations.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.batch_decode(outputs[:, input_ids.shape[1]:-1])[0].strip())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaacfe6f-6679-4a72-8429-c9e4324268f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5433da1b-28f1-44ad-a4b4-e2adeda0bd1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5bf5f0-45ea-4450-bc30-b2ae78a6966c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3a229f-e164-4768-8c54-3e7fa7c8194e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
